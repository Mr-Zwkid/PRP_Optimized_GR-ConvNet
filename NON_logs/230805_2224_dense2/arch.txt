----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 16, 224, 224]           5,200
       BatchNorm2d-2         [-1, 16, 224, 224]              32
              ReLU-3         [-1, 16, 224, 224]               0
              Conv-4         [-1, 16, 224, 224]               0
            Conv2d-5         [-1, 32, 112, 112]           8,224
       BatchNorm2d-6         [-1, 32, 112, 112]              64
              ReLU-7         [-1, 32, 112, 112]               0
              Conv-8         [-1, 32, 112, 112]               0
       BatchNorm2d-9         [-1, 32, 112, 112]              64
             ReLU-10         [-1, 32, 112, 112]               0
           Conv2d-11         [-1, 16, 112, 112]             512
      BatchNorm2d-12         [-1, 16, 112, 112]              32
             ReLU-13         [-1, 16, 112, 112]               0
           Conv2d-14         [-1, 32, 112, 112]           4,608
      Dense_Layer-15         [-1, 64, 112, 112]               0
      BatchNorm2d-16         [-1, 64, 112, 112]             128
             ReLU-17         [-1, 64, 112, 112]               0
           Conv2d-18         [-1, 16, 112, 112]           1,024
      BatchNorm2d-19         [-1, 16, 112, 112]              32
             ReLU-20         [-1, 16, 112, 112]               0
           Conv2d-21         [-1, 32, 112, 112]           4,608
      Dense_Layer-22         [-1, 96, 112, 112]               0
      BatchNorm2d-23         [-1, 96, 112, 112]             192
             ReLU-24         [-1, 96, 112, 112]               0
           Conv2d-25         [-1, 16, 112, 112]           1,536
      BatchNorm2d-26         [-1, 16, 112, 112]              32
             ReLU-27         [-1, 16, 112, 112]               0
           Conv2d-28         [-1, 32, 112, 112]           4,608
      Dense_Layer-29        [-1, 128, 112, 112]               0
     _Dense_Block-30        [-1, 128, 112, 112]               0
      BatchNorm2d-31        [-1, 128, 112, 112]             256
             ReLU-32        [-1, 128, 112, 112]               0
           Conv2d-33         [-1, 32, 112, 112]           4,128
        AvgPool2d-34           [-1, 32, 56, 56]               0
       Transition-35           [-1, 32, 56, 56]               0
      Dense_Block-36           [-1, 32, 56, 56]               0
      BatchNorm2d-37           [-1, 32, 56, 56]              64
             ReLU-38           [-1, 32, 56, 56]               0
           Conv2d-39           [-1, 16, 56, 56]             512
      BatchNorm2d-40           [-1, 16, 56, 56]              32
             ReLU-41           [-1, 16, 56, 56]               0
           Conv2d-42           [-1, 32, 56, 56]           4,608
      Dense_Layer-43           [-1, 64, 56, 56]               0
      BatchNorm2d-44           [-1, 64, 56, 56]             128
             ReLU-45           [-1, 64, 56, 56]               0
           Conv2d-46           [-1, 16, 56, 56]           1,024
      BatchNorm2d-47           [-1, 16, 56, 56]              32
             ReLU-48           [-1, 16, 56, 56]               0
           Conv2d-49           [-1, 32, 56, 56]           4,608
      Dense_Layer-50           [-1, 96, 56, 56]               0
     _Dense_Block-51           [-1, 96, 56, 56]               0
      BatchNorm2d-52           [-1, 96, 56, 56]             192
             ReLU-53           [-1, 96, 56, 56]               0
           Conv2d-54           [-1, 64, 56, 56]           6,208
       Transition-55           [-1, 64, 56, 56]               0
      Dense_Block-56           [-1, 64, 56, 56]               0
      BatchNorm2d-57           [-1, 64, 56, 56]             128
             ReLU-58           [-1, 64, 56, 56]               0
           Conv2d-59           [-1, 16, 56, 56]           1,024
      BatchNorm2d-60           [-1, 16, 56, 56]              32
             ReLU-61           [-1, 16, 56, 56]               0
           Conv2d-62           [-1, 32, 56, 56]           4,608
      Dense_Layer-63           [-1, 96, 56, 56]               0
      BatchNorm2d-64           [-1, 96, 56, 56]             192
             ReLU-65           [-1, 96, 56, 56]               0
           Conv2d-66           [-1, 16, 56, 56]           1,536
      BatchNorm2d-67           [-1, 16, 56, 56]              32
             ReLU-68           [-1, 16, 56, 56]               0
           Conv2d-69           [-1, 32, 56, 56]           4,608
      Dense_Layer-70          [-1, 128, 56, 56]               0
      BatchNorm2d-71          [-1, 128, 56, 56]             256
             ReLU-72          [-1, 128, 56, 56]               0
           Conv2d-73           [-1, 16, 56, 56]           2,048
      BatchNorm2d-74           [-1, 16, 56, 56]              32
             ReLU-75           [-1, 16, 56, 56]               0
           Conv2d-76           [-1, 32, 56, 56]           4,608
      Dense_Layer-77          [-1, 160, 56, 56]               0
     _Dense_Block-78          [-1, 160, 56, 56]               0
      BatchNorm2d-79          [-1, 160, 56, 56]             320
             ReLU-80          [-1, 160, 56, 56]               0
           Conv2d-81           [-1, 64, 56, 56]          10,304
        AvgPool2d-82           [-1, 64, 28, 28]               0
       Transition-83           [-1, 64, 28, 28]               0
      Dense_Block-84           [-1, 64, 28, 28]               0
      BatchNorm2d-85           [-1, 64, 28, 28]             128
             ReLU-86           [-1, 64, 28, 28]               0
           Conv2d-87           [-1, 16, 28, 28]           1,024
      BatchNorm2d-88           [-1, 16, 28, 28]              32
             ReLU-89           [-1, 16, 28, 28]               0
           Conv2d-90           [-1, 32, 28, 28]           4,608
      Dense_Layer-91           [-1, 96, 28, 28]               0
      BatchNorm2d-92           [-1, 96, 28, 28]             192
             ReLU-93           [-1, 96, 28, 28]               0
           Conv2d-94           [-1, 16, 28, 28]           1,536
      BatchNorm2d-95           [-1, 16, 28, 28]              32
             ReLU-96           [-1, 16, 28, 28]               0
           Conv2d-97           [-1, 32, 28, 28]           4,608
      Dense_Layer-98          [-1, 128, 28, 28]               0
     _Dense_Block-99          [-1, 128, 28, 28]               0
     BatchNorm2d-100          [-1, 128, 28, 28]             256
            ReLU-101          [-1, 128, 28, 28]               0
          Conv2d-102           [-1, 64, 28, 28]           8,256
      Transition-103           [-1, 64, 28, 28]               0
     Dense_Block-104           [-1, 64, 28, 28]               0
 ConvTranspose2d-105           [-1, 32, 56, 56]          32,800
     BatchNorm2d-106           [-1, 32, 56, 56]              64
 ConvTranspose2d-107         [-1, 16, 112, 112]           8,208
     BatchNorm2d-108         [-1, 16, 112, 112]              32
 ConvTranspose2d-109         [-1, 16, 225, 225]           4,112
     BatchNorm2d-110         [-1, 16, 225, 225]              32
 ConvTranspose2d-111         [-1, 16, 225, 225]          20,752
         Dropout-112         [-1, 16, 225, 225]               0
          Conv2d-113          [-1, 1, 224, 224]              65
         Dropout-114         [-1, 16, 225, 225]               0
          Conv2d-115          [-1, 1, 224, 224]              65
         Dropout-116         [-1, 16, 225, 225]               0
          Conv2d-117          [-1, 1, 224, 224]              65
         Dropout-118         [-1, 16, 225, 225]               0
          Conv2d-119          [-1, 1, 224, 224]              65
================================================================
Total params: 169,348
Trainable params: 169,348
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.77
Forward/backward pass size (MB): 289.79
Params size (MB): 0.65
Estimated Total Size (MB): 291.20
----------------------------------------------------------------
