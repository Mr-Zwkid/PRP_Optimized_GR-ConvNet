----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 16, 224, 224]           5,200
       BatchNorm2d-2         [-1, 16, 224, 224]              32
              ReLU-3         [-1, 16, 224, 224]               0
              Conv-4         [-1, 16, 224, 224]               0
            Conv2d-5         [-1, 32, 112, 112]           8,224
       BatchNorm2d-6         [-1, 32, 112, 112]              64
              ReLU-7         [-1, 32, 112, 112]               0
              Conv-8         [-1, 32, 112, 112]               0
       BatchNorm2d-9         [-1, 32, 112, 112]              64
             ReLU-10         [-1, 32, 112, 112]               0
           Conv2d-11         [-1, 16, 112, 112]             512
      BatchNorm2d-12         [-1, 16, 112, 112]              32
             ReLU-13         [-1, 16, 112, 112]               0
           Conv2d-14         [-1, 32, 112, 112]           4,608
      Dense_Layer-15         [-1, 64, 112, 112]               0
      BatchNorm2d-16         [-1, 64, 112, 112]             128
             ReLU-17         [-1, 64, 112, 112]               0
           Conv2d-18         [-1, 16, 112, 112]           1,024
      BatchNorm2d-19         [-1, 16, 112, 112]              32
             ReLU-20         [-1, 16, 112, 112]               0
           Conv2d-21         [-1, 32, 112, 112]           4,608
      Dense_Layer-22         [-1, 96, 112, 112]               0
      BatchNorm2d-23         [-1, 96, 112, 112]             192
             ReLU-24         [-1, 96, 112, 112]               0
           Conv2d-25         [-1, 16, 112, 112]           1,536
      BatchNorm2d-26         [-1, 16, 112, 112]              32
             ReLU-27         [-1, 16, 112, 112]               0
           Conv2d-28         [-1, 32, 112, 112]           4,608
      Dense_Layer-29        [-1, 128, 112, 112]               0
     _Dense_Block-30        [-1, 128, 112, 112]               0
      BatchNorm2d-31        [-1, 128, 112, 112]             256
             ReLU-32        [-1, 128, 112, 112]               0
           Conv2d-33         [-1, 32, 112, 112]           4,128
        AvgPool2d-34           [-1, 32, 56, 56]               0
       Transition-35           [-1, 32, 56, 56]               0
      Dense_Block-36           [-1, 32, 56, 56]               0
      BatchNorm2d-37           [-1, 32, 56, 56]              64
             ReLU-38           [-1, 32, 56, 56]               0
           Conv2d-39           [-1, 16, 56, 56]             512
      BatchNorm2d-40           [-1, 16, 56, 56]              32
             ReLU-41           [-1, 16, 56, 56]               0
           Conv2d-42           [-1, 32, 56, 56]           4,608
      Dense_Layer-43           [-1, 64, 56, 56]               0
      BatchNorm2d-44           [-1, 64, 56, 56]             128
             ReLU-45           [-1, 64, 56, 56]               0
           Conv2d-46           [-1, 16, 56, 56]           1,024
      BatchNorm2d-47           [-1, 16, 56, 56]              32
             ReLU-48           [-1, 16, 56, 56]               0
           Conv2d-49           [-1, 32, 56, 56]           4,608
      Dense_Layer-50           [-1, 96, 56, 56]               0
      BatchNorm2d-51           [-1, 96, 56, 56]             192
             ReLU-52           [-1, 96, 56, 56]               0
           Conv2d-53           [-1, 16, 56, 56]           1,536
      BatchNorm2d-54           [-1, 16, 56, 56]              32
             ReLU-55           [-1, 16, 56, 56]               0
           Conv2d-56           [-1, 32, 56, 56]           4,608
      Dense_Layer-57          [-1, 128, 56, 56]               0
     _Dense_Block-58          [-1, 128, 56, 56]               0
      BatchNorm2d-59          [-1, 128, 56, 56]             256
             ReLU-60          [-1, 128, 56, 56]               0
           Conv2d-61           [-1, 64, 56, 56]           8,256
       Transition-62           [-1, 64, 56, 56]               0
      Dense_Block-63           [-1, 64, 56, 56]               0
      BatchNorm2d-64           [-1, 64, 56, 56]             128
             ReLU-65           [-1, 64, 56, 56]               0
           Conv2d-66           [-1, 16, 56, 56]           1,024
      BatchNorm2d-67           [-1, 16, 56, 56]              32
             ReLU-68           [-1, 16, 56, 56]               0
           Conv2d-69           [-1, 32, 56, 56]           4,608
      Dense_Layer-70           [-1, 96, 56, 56]               0
      BatchNorm2d-71           [-1, 96, 56, 56]             192
             ReLU-72           [-1, 96, 56, 56]               0
           Conv2d-73           [-1, 16, 56, 56]           1,536
      BatchNorm2d-74           [-1, 16, 56, 56]              32
             ReLU-75           [-1, 16, 56, 56]               0
           Conv2d-76           [-1, 32, 56, 56]           4,608
      Dense_Layer-77          [-1, 128, 56, 56]               0
      BatchNorm2d-78          [-1, 128, 56, 56]             256
             ReLU-79          [-1, 128, 56, 56]               0
           Conv2d-80           [-1, 16, 56, 56]           2,048
      BatchNorm2d-81           [-1, 16, 56, 56]              32
             ReLU-82           [-1, 16, 56, 56]               0
           Conv2d-83           [-1, 32, 56, 56]           4,608
      Dense_Layer-84          [-1, 160, 56, 56]               0
     _Dense_Block-85          [-1, 160, 56, 56]               0
      BatchNorm2d-86          [-1, 160, 56, 56]             320
             ReLU-87          [-1, 160, 56, 56]               0
           Conv2d-88           [-1, 64, 56, 56]          10,304
        AvgPool2d-89           [-1, 64, 28, 28]               0
       Transition-90           [-1, 64, 28, 28]               0
      Dense_Block-91           [-1, 64, 28, 28]               0
  ConvTranspose2d-92           [-1, 32, 56, 56]          32,800
      BatchNorm2d-93           [-1, 32, 56, 56]              64
  ConvTranspose2d-94         [-1, 16, 112, 112]           8,208
      BatchNorm2d-95         [-1, 16, 112, 112]              32
  ConvTranspose2d-96         [-1, 16, 225, 225]           4,112
      BatchNorm2d-97         [-1, 16, 225, 225]              32
  ConvTranspose2d-98         [-1, 16, 225, 225]          20,752
          Dropout-99         [-1, 16, 225, 225]               0
          Conv2d-100          [-1, 1, 224, 224]              65
         Dropout-101         [-1, 16, 225, 225]               0
          Conv2d-102          [-1, 1, 224, 224]              65
         Dropout-103         [-1, 16, 225, 225]               0
          Conv2d-104          [-1, 1, 224, 224]              65
         Dropout-105         [-1, 16, 225, 225]               0
          Conv2d-106          [-1, 1, 224, 224]              65
================================================================
Total params: 157,156
Trainable params: 157,156
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.77
Forward/backward pass size (MB): 294.00
Params size (MB): 0.60
Estimated Total Size (MB): 295.37
----------------------------------------------------------------
